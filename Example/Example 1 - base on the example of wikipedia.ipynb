{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example - base on the example of wikipedia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.HMM类的实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class HMM:\n",
    "    '''HMM类实现'''\n",
    "    def __init__(self, initVectorPi, transitionMatrix, emissionMatrix):\n",
    "        self.initVectorPi = initVectorPi\n",
    "        self.transitionMatrix = transitionMatrix\n",
    "        self.emissionMatrix = emissionMatrix\n",
    "    \n",
    "    @property #返回隐藏状态数目\n",
    "    def statesNumber(self):\n",
    "        return self.transitionMatrix.shape[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.wikipedia的例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Wikipedia中的例子：https://en.wikipedia.org/wiki/Viterbi_algorithm#Example\n",
    "############################################\n",
    "'''\n",
    "这里用数字代表字母\n",
    "隐藏状态：0=Healthy, 1=Fever\n",
    "观察状态：0=Normal, 1=Cold, 2=Dizzy\n",
    "'''\n",
    "hiddenStates=['Healthy','Fever']\n",
    "observStates=['Normal','Cold','Dizzy']\n",
    "\n",
    "wiki_initVectorPi1 = np.array([0.6, 0.4])#初始概率向量pi\n",
    "wiki_transitionMatrix1 = np.array([[0.7, 0.3],#转移矩阵\n",
    "                                  [0.4, 0.6]]) \n",
    "wiki_emissionMatrix1 = np.array([[0.5, 0.4, 0.1], #发射矩阵（或混淆矩阵）\n",
    "                                [0.1, 0.3, 0.6]]) \n",
    "wiki_observations1 = [0, 1, 2] # 观察序列：Normal、Cold、Dizzy\n",
    "\n",
    "wiki_hmm1 = HMM(wiki_initVectorPi1, wiki_transitionMatrix1, wiki_emissionMatrix1)\n",
    "############################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.viterbi算法实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Normal       Cold      Dizzy\n",
      " Healthy:  0.300000   0.084000   0.005880\n",
      "   Fever:  0.040000   0.027000   0.015120\n",
      "The most possiblehidden state sequence is  ['Healthy', 'Healthy', 'Fever'] with highest probability of 0.015120\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def viterbi(hmm, observations):\n",
    "    '''Viterbi算法实现\n",
    "    输入：HMM模型（包含初始向量pi，转移矩阵A、发射矩阵B）、观察序列\n",
    "    输出：符合输入观察序列的最佳隐藏状态序列，储存每个时刻每个状态的概率值的矩阵\n",
    "    '''\n",
    "    #计算t=1时刻（从1开始计数）的局部概率 /delta_1(i) \n",
    "    allProbs = np.zeros((hmm.statesNumber,len(observations))) #用于存储每个阶段的概率值\n",
    "    probs = hmm.emissionMatrix[:, observations[0]] * hmm.initVectorPi #对应元素相乘\n",
    "    allProbs[:,0] = probs\n",
    "    probs = probs.reshape(-1,1) #将行向量转换成列向量\n",
    "    stack = [] #用来储存反向指针，即回溯得到最佳隐藏序列时会用到\n",
    "    \n",
    "    #计算t>1时刻的局部概率 /delta_t(i)\n",
    "    t=1\n",
    "    for obs in observations[1:]:\n",
    "        #对应元素相乘，得到上一个时刻的局部概率 /delta_{t-1}(i) 和转移概率 a_{ij} 的对应乘积\n",
    "        transProbs = hmm.transitionMatrix * probs\n",
    "        #对于每一列（每个隐藏状态），找出使得 当前隐藏状态最大概率发生 的上一个时刻的隐藏状态的数字下标\n",
    "        maxProbsIndex = np.argmax(transProbs, axis=0)\n",
    "        #将反向指针压入栈\n",
    "        stack.append(maxProbsIndex)\n",
    "        #更新当前时间的局部概率\n",
    "        probs = hmm.emissionMatrix[:, obs] * transProbs[maxProbsIndex, np.arange(hmm.statesNumber)]\n",
    "        allProbs[:,t] = probs\n",
    "        probs = probs.reshape(-1,1) #将行向量转换成列向量\n",
    "        t+=1\n",
    "\n",
    "    stateSeq = [np.argmax(probs)] #找出最大概率对应隐藏状态的下标\n",
    "    \n",
    "    #反向回溯\n",
    "    while stack:\n",
    "        #得到当前栈顶元素，并将该元素从栈顶去除\n",
    "        maxProbsIndex = stack.pop()\n",
    "        #依次将使得后一个时刻最大概率发生的隐藏状态添加到stateSeq中\n",
    "        stateSeq.append(maxProbsIndex[stateSeq[-1]]) \n",
    "\n",
    "    stateSeq.reverse() #反转得到按时刻从早到晚的 最佳隐藏状态序列\n",
    "    \n",
    "    return stateSeq,allProbs\n",
    "\n",
    "seq, probs = viterbi(wiki_hmm1, wiki_observations1) # 调用算法\n",
    "\n",
    "############   结果输出  #############\n",
    "print(' '*8 + \" \".join((\"%10s\" % obs) for obs in observStates)) #输出所有观察状态\n",
    "#输出每个阶段每个状态的概率值\n",
    "for i in range(len(hiddenStates)):\n",
    "    print(\"%8s:\" % hiddenStates[i] + \" \".join((\"%10f\" % prob) for prob in probs[i]))\n",
    "#输出最佳隐藏序列 以及 对应的最高概率\n",
    "print(\"The most possiblehidden state sequence is \" , [hiddenStates[i] for i in seq], \\\n",
    "      \"with highest probability of %8f\" % max(probs[:,-1]))\n",
    "############   结果输出  #############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可见，输出最佳隐藏序列与wikipedia中的答案（如下）一致。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "$ python viterbi_example.py\n",
    "         0          1          2\n",
    "Healthy: 0.30000 0.08400 0.00588\n",
    "Fever: 0.04000 0.02700 0.01512\n",
    "The steps of states are Healthy Healthy Fever with highest probability of 0.01512\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.前向-后向算法实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03628\n",
      "0.03628\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def forward(hmm,observations):\n",
    "    '''前向算法实现\n",
    "    输入：HMM模型（包含初始向量pi，转移矩阵A、发射矩阵B）、观察序列\n",
    "    输出：输入观察序列在该HMM模型发生的概率、中间概率矩阵(alpha)\n",
    "    '''\n",
    "    rowNum = hmm.statesNumber\n",
    "    colNum = len(observations)\n",
    "    alpha = np.zeros((rowNum,colNum)) #二维矩阵，储存 T个时刻的alpha值\n",
    "    \n",
    "    #求t=1（t从1开始计数）时刻的alpha,即是 初始的概率与对应发射概率相乘\n",
    "    alpha[:,0] = hmm.initVectorPi * np.transpose(hmm.emissionMatrix[:,observations[0]]) \n",
    "    \n",
    "    #求 t=2,...,T 的alpha值\n",
    "    for t in range(1,colNum):          \n",
    "        for j in range(rowNum): \n",
    "            #求和符号可用点乘实现\n",
    "            alpha[j,t] = hmm.emissionMatrix[j,observations[t]] * np.dot(alpha[:,t-1],hmm.transitionMatrix[:,j])\n",
    "    #对最后一列alpha值求和\n",
    "    ans=sum(alpha[:,colNum-1])\n",
    "    return ans,alpha\n",
    "\n",
    "def backward(hmm,observations):\n",
    "    '''后向算法实现\n",
    "    输入：HMM模型（包含初始向量pi，转移矩阵A、发射矩阵B）、观察序列\n",
    "    输出：输入观察序列在该HMM模型发生的概率、中间概率矩阵(beta)\n",
    "    '''    \n",
    "    rowNum = hmm.statesNumber\n",
    "    colNum = len(observations)\n",
    "    beta = np.zeros((rowNum,colNum)) #二维矩阵，储存 T个时刻的beta值\n",
    "    #t=T时，每一个元素赋值为1\n",
    "    beta[:,colNum-1] = 1                  \n",
    "    #求 t<T 时的beta值\n",
    "    for t in reversed(range(colNum-1)):\n",
    "        for i in range(rowNum):\n",
    "            beta[i,t] = np.sum(beta[:,t+1] * hmm.transitionMatrix[i,:] * hmm.emissionMatrix[:,observations[t+1]])\n",
    "    #对第一列beta值求和\n",
    "    ans = np.sum(hmm.initVectorPi * beta[:,0] * hmm.emissionMatrix[:,observations[0]])\n",
    "    return ans,beta\n",
    "\n",
    "print(forward(wiki_hmm1, wiki_observations1)[0])\n",
    "print(backward(wiki_hmm1, wiki_observations1)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可见，前向算法和后向算法输出的结果是一样的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.Baum Welch算法实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def forward(hmm,observations):\n",
    "    '''前向算法实现\n",
    "    输入：HMM模型（包含初始向量pi，转移矩阵A、发射矩阵B）、观察序列\n",
    "    输出：输入观察序列在该HMM模型发生的概率、中间概率矩阵(alpha)\n",
    "    '''\n",
    "    rowNum = hmm.statesNumber\n",
    "    colNum = len(observations)\n",
    "    alpha = np.zeros((rowNum,colNum)) #二维矩阵，储存 T个时刻的alpha值\n",
    "    \n",
    "    #求t=1（t从1开始计数）时刻的alpha,即是 初始的概率与对应发射概率相乘\n",
    "    alpha[:,0] = hmm.initVectorPi * np.transpose(hmm.emissionMatrix[:,observations[0]]) \n",
    "    \n",
    "    #求 t=2,...,T 的alpha值\n",
    "    for t in range(1,colNum):          \n",
    "        for j in range(rowNum): \n",
    "            #求和符号可用点乘实现\n",
    "            alpha[j,t] = hmm.emissionMatrix[j,observations[t]] * np.dot(alpha[:,t-1],hmm.transitionMatrix[:,j])\n",
    "    #对最后一列alpha值求和\n",
    "    ans=sum(alpha[:,colNum-1])\n",
    "    return ans,alpha\n",
    "\n",
    "def backward(hmm,observations):\n",
    "    '''后向算法实现\n",
    "    输入：HMM模型（包含初始向量pi，转移矩阵A、发射矩阵B）、观察序列\n",
    "    输出：输入观察序列在该HMM模型发生的概率、中间概率矩阵(beta)\n",
    "    '''    \n",
    "    rowNum = hmm.statesNumber\n",
    "    colNum = len(observations)\n",
    "    beta = np.zeros((rowNum,colNum)) #二维矩阵，储存 T个时刻的beta值\n",
    "    #t=T时，每一个元素赋值为1\n",
    "    beta[:,colNum-1] = 1                  \n",
    "    #求 t<T 时的beta值\n",
    "    for t in reversed(range(colNum-1)):\n",
    "        for i in range(rowNum):\n",
    "            beta[i,t] = np.sum(beta[:,t+1] * hmm.transitionMatrix[i,:] * hmm.emissionMatrix[:,observations[t+1]])\n",
    "    #对第一列beta值求和\n",
    "    ans = np.sum(hmm.initVectorPi * beta[:,0] * hmm.emissionMatrix[:,observations[0]])\n",
    "    return ans,beta\n",
    "\n",
    "def getGamma(hmm,alpha,beta):\n",
    "    '''计算gamma矩阵\n",
    "    输入：HMM模型（包含初始向量pi，转移矩阵A、发射矩阵B）、alpha矩阵、beta矩阵\n",
    "    输出：gamma矩阵\n",
    "    '''\n",
    "    gamma = np.zeros(alpha.shape) #gamma的维度时和alpha一样的\n",
    "    gamma = alpha * beta #矩阵对应元素相乘\n",
    "    gamma = gamma / np.sum(gamma,0)\n",
    "    return gamma\n",
    "\n",
    "def getXi(hmm, observations, alpha, beta):\n",
    "    '''\n",
    "    计算xi矩阵\n",
    "    输入：HMM模型（包含初始向量pi，转移矩阵A、发射矩阵B）、观察序列、alpha矩阵、beta矩阵\n",
    "    输出：xi矩阵\n",
    "    '''\n",
    "    colNum = len(observations)\n",
    "    rowNum = hmm.statesNumber\n",
    "    xi = np.zeros((rowNum, rowNum, colNum-1))\n",
    "\n",
    "    for t in range(0, colNum-1):        \n",
    "        for i in range(0, rowNum):\n",
    "            for j in range(0, rowNum):\n",
    "                xi[i,j,t] = alpha[i,t] * hmm.transitionMatrix[i,j] * beta[j,t+1] * \\\n",
    "                            hmm.emissionMatrix[j,observations[t+1]-1] \n",
    "        xi[:,:,t] /= np.sum(xi[:,:,t])    #modify\n",
    "    return xi\n",
    "\n",
    "def baumWelch(hmm, observations):\n",
    "     pass\n",
    "    \n",
    "#todo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 关于argmax函数\n",
    "\n",
    "这个函数有点不熟悉，这里备注下使用方法。\n",
    "\n",
    "**numpy.argmax(a, axis=None, out=None) ** ： 返回沿轴axis最大值的索引。\n",
    "\n",
    "**Parameters**: \n",
    "a : array_like 数组 \n",
    "axis : int, 可选，默认情况下，索引的是平铺的数组，否则沿指定的轴。 \n",
    "out : array, 可选，如果提供，结果以合适的形状和类型被插入到此数组中。 \n",
    "\n",
    "**Returns**: \n",
    "index_array : ndarray of ints,索引数组。它具有与a.shape相同的形状，其中axis被移除。 \n",
    "\n",
    "例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.array([[0, 1, 2],\n",
    "              [3, 4, 5]])\n",
    "np.argmax(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(a, axis=0)#0代表列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(a, axis=1)#1代表行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.array([0, 5, 2, 3, 4, 5])\n",
    "np.argmax(b) # 只返回第一次出现的最大值的索引"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
